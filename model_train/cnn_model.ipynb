{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNetV2 model \n",
    "## outline of the code\n",
    "\n",
    "1. Import necessary libraries:\n",
    "* Import TensorFlow, Keras, and other necessary libraries for building and training the model.\n",
    "\n",
    "2. Load the dataset:\n",
    "* Load the face mask dataset, which includes images of people with and without masks.\n",
    "\n",
    "3. Data preprocessing:\n",
    "\n",
    "* Resize the images to a consistent size (e.g., 224x224 pixels) and normalize the pixel values.\n",
    "* Apply data augmentation techniques (e.g., rotation, flipping, zooming) to artificially increase the size and diversity of the dataset.\n",
    "* Split the dataset into training and test sets for model evaluation.\n",
    "\n",
    "4. Create a base model with transfer learning:\n",
    "\n",
    "* Load a pre-trained model (MobileNetV2) as the base model.\n",
    "* Remove the top layers to use the pre-trained model as a feature extractor.\n",
    "\n",
    "5. Add regularization and custom layers:\n",
    "\n",
    "* Apply regularization techniques (dropout) to reduce overfitting.\n",
    "* Add custom layers on top of the base model to create a new model architecture tailored for the face mask classification task.\n",
    "\n",
    "6. Compile the model:\n",
    "\n",
    "* Compile the model with an optimizer (Adam), loss function (binary_crossentropy), and metric (accuracy).\n",
    "\n",
    "\n",
    "7. Train the model:\n",
    "\n",
    "* Train the model on the training dataset for a specified number of epochs, using the test dataset for validation.\n",
    "\n",
    "8. Evaluate the model:\n",
    "\n",
    "* Assess the model's performance on the test dataset and report the test accuracy.\n",
    "\n",
    "\n",
    "In this repo, we implements a face mask detection model using transfer learning and data augmentation, with regularization techniques and a custom model architecture. The model is trained on a dataset of images of people with and without masks and evaluated on a separate test dataset to measure its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'dalle2images'\n",
    "real_image_paths = []\n",
    "fake_image_paths = []\n",
    "real_labels = []\n",
    "fake_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the images in your S3 bucket and append them to their respective lists:\n",
    "for obj in s3.Bucket(bucket_name).objects.all():\n",
    "    if obj.key.endswith('.png') and obj.key.startswith('real'):\n",
    "        real_image_paths.append(obj.key)\n",
    "        real_labels.append(0)\n",
    "    elif obj.key.endswith('.png') and obj.key.startswith('fake'):\n",
    "        fake_image_paths.append(obj.key)\n",
    "        fake_labels.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 1000 images (500 real, 500 fake) from your bucket\n",
    "n_images = 100\n",
    "n_real = n_fake = n_images // 2\n",
    "real_samples = np.random.choice(real_image_paths, n_real, replace=False)\n",
    "fake_samples = np.random.choice(fake_image_paths, n_fake, replace=False)\n",
    "sample_paths = np.concatenate([real_samples, fake_samples])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "image_size = (224, 224)\n",
    "\n",
    "for i, path in enumerate(sample_paths):\n",
    "    img = s3.Object(bucket_name, path)\n",
    "    img = Image.open(img.get()['Body'])\n",
    "    img = img.resize(image_size, Image.ANTIALIAS)\n",
    "    img = np.array(img)\n",
    "    faces = RetinaFace.detect_faces(img)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        continue\n",
    "\n",
    "    img = tf.cast(img, dtype=tf.float32)\n",
    "    images.append(img)\n",
    "    labels.append(0 if path.startswith('real') else 1)\n",
    "\n",
    "images = np.stack(images)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_images), reshuffle_each_iteration=True)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 6s 747ms/step - loss: 1.9344 - accuracy: 0.4500 - val_loss: 1.3408 - val_accuracy: 0.5500\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 297ms/step - loss: 1.6811 - accuracy: 0.5125 - val_loss: 1.3065 - val_accuracy: 0.6500\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 1.5161 - accuracy: 0.5250 - val_loss: 1.3130 - val_accuracy: 0.6500\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 311ms/step - loss: 1.4481 - accuracy: 0.5875 - val_loss: 1.3961 - val_accuracy: 0.6000\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 306ms/step - loss: 1.4575 - accuracy: 0.5250 - val_loss: 1.3506 - val_accuracy: 0.6000\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 325ms/step - loss: 1.3380 - accuracy: 0.6000 - val_loss: 1.2909 - val_accuracy: 0.6500\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 334ms/step - loss: 1.2294 - accuracy: 0.6500 - val_loss: 1.2412 - val_accuracy: 0.6500\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 310ms/step - loss: 1.3314 - accuracy: 0.5250 - val_loss: 1.1977 - val_accuracy: 0.6500\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 312ms/step - loss: 1.2918 - accuracy: 0.5375 - val_loss: 1.1651 - val_accuracy: 0.7000\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 323ms/step - loss: 1.1928 - accuracy: 0.5750 - val_loss: 1.1492 - val_accuracy: 0.7000\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 1.1492 - accuracy: 0.7000\n",
      "Test accuracy: 70.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the pre-trained MobileNetV2 model without the top layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model's layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add the data augmentation layer\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.2)\n",
    "])\n",
    "\n",
    "# Define the regularization strength\n",
    "reg_strength = 0.001\n",
    "\n",
    "# Create a new model using the base model and adding custom top layers\n",
    "model = tf.keras.models.Sequential([\n",
    "    data_augmentation,\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(reg_strength)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=l2(reg_strength)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=l2(reg_strength)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "history = model.fit(train_dataset, epochs=epochs, validation_data=test_dataset)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(\"Test accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
